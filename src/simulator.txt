syntax = "proto3";

package roadwork.services.simulator_service;

//import "roadwork/messages/ActionSpace";
//import "roadwork/messages/ObservationSpace";
//import "roadwork/messages/RewardRange";

// import "google/protobuf/any.proto";

// See: https://developers.google.com/protocol-buffers/docs/proto#scalar
// https://github.com/openai/gym/blob/master/gym/core.py
message BaseRequest {
    string instanceId = 1;
}

message BaseResponse {}

message SimulatorStepRequest {
    string instanceId = 1; // The instanceId of the environment
    int32 action = 2; // The action provided by the agent (@todo: the datatype doesn't exist...)
    bool render = 3; // Do we need to render? (@todo)
}

message SimulatorStepResponse {
    float reward = 1; // The reward received after taking the previous action
    bool isDone = 2; // Has the episode ended?
    map<string, string> info = 3; // Diagnostic information

    oneof observation {
        SpaceObservationDiscrete observationDiscrete = 4;
        SpaceObservationBox observationBox = 5;
    }
}

message SpaceObservationDiscrete {
    int32 observation = 1;
}

message SpaceObservationBox {
    repeated uint32 dimensions = 1;
    repeated double observation = 2 [packed=true]; // See "packed": https://developers.google.com/protocol-buffers/docs/proto#options
}

message SimulatorResetRequest {
    string instanceId = 1;
}

message SimulatorResetResponse {
    repeated double observation = 1; // The initial observation
}

message SimulatorRenderRequest {
    string instanceId = 1; // The instanceId of the environment
    string mode = 2;
}

message SimulatorRenderResponse {}

message SimulatorCloseRequest {
    string instanceId = 1; // The instanceId of the environment
}

message SimulatorCloseResponse {}

message SimulatorCreateRequest {
    string envId = 1;
}

message SimulatorCreateResponse {
    string instanceId = 1;
}

message SimulatorActionSpaceSampleRequest {
    string instanceId = 1;
}

message SimulatorActionSpaceSampleResponse {
    int32 action = 1; // Note: Serialized as bytes!
}

message SimulatorActionSpaceInfoRequest {
    string instanceId = 1;
}

message SimulatorActionSpaceInfoResponse {
    string name = 1;
    oneof actionSpaceType {
        SpaceTypeDiscrete typeDiscrete = 2;
        SpaceTypeBox typeBox = 3;
    }
}

message SimulatorObservationSpaceInfoRequest {
    string instanceId = 1;
}

message SimulatorObservationSpaceInfoResponse {
    string name = 1;
    oneof observationType {
        SpaceTypeDiscrete typeDiscrete = 2;
        SpaceTypeBox typeBox = 3;
    }
}

message SpaceTypeDiscrete {
    int32 n = 1;
}

message SpaceTypeBox {
    repeated int32 shape = 1; // Note: we use .extend() to append an entire list to this
    repeated double low = 2;
    repeated double high = 3;
}

service Simulator {
    rpc Create(SimulatorCreateRequest) returns (SimulatorCreateResponse) {}

    // Run one timestep of the environment's dynamics. When end of
    // episode is reached, you are responsible for calling `reset()`
    // to reset this environment's state.
    rpc Step(SimulatorStepRequest) returns (SimulatorStepResponse) {}

    // Resets the state of the environment and returns an initial observation.
    rpc Reset(SimulatorResetRequest) returns (SimulatorResetResponse) {}

    // Renders the environment.
    // The set of supported modes varies per environment. (And some
    // environments do not support rendering at all.) By convention,
    // if mode is:
    // - human: render to the current display or terminal and
    //     return nothing. Usually for human consumption.
    // - rgb_array: Return an numpy.ndarray with shape (x, y, 3),
    //     representing RGB values for an x-by-y pixel image, suitable
    //     for turning into a video.
    // - ansi: Return a string (str) or StringIO.StringIO containing a
    //     terminal-style text representation. The text can include newlines
    //     and ANSI escape sequences (e.g. for colors).
    // Note:
    //     Make sure that your class's metadata 'render.modes' key includes
    //         the list of supported modes. It's recommended to call super()
    //         in implementations to use the functionality of this method.
    // Args:
    //     mode (str): the mode to render with
    // Example:
    // class MyEnv(Env):
    //     metadata = {'render.modes': ['human', 'rgb_array']}
    //     def render(self, mode='human'):
    //         if mode == 'rgb_array':
    //             return np.array(...) # return RGB frame suitable for video
    //         elif mode == 'human':
    //             ... # pop up a window and render
    //         else:
    //             super(MyEnv, self).render(mode=mode) # just raise an exception
    rpc Render(SimulatorRenderRequest) returns (SimulatorRenderResponse) {}

    // Override close in your subclass to perform any necessary cleanup.
    // Environments will automatically close() themselves when
    // garbage collected or when the program exits.
    rpc Close(SimulatorCloseRequest) returns (SimulatorCloseResponse) {}

    rpc ActionSpaceSample(SimulatorActionSpaceSampleRequest) returns (SimulatorActionSpaceSampleResponse) {}
    rpc ActionSpaceInfo(SimulatorActionSpaceInfoRequest) returns (SimulatorActionSpaceInfoResponse) {}
    rpc ObservationSpaceInfo(SimulatorObservationSpaceInfoRequest) returns (SimulatorObservationSpaceInfoResponse) {}

    rpc MonitorStart(BaseRequest) returns (BaseResponse) {}
    rpc MonitorStop(BaseRequest) returns (BaseResponse) {}
}